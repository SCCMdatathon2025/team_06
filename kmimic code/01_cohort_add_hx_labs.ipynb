{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b6bfbb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas numpy matplotlib seaborn pyarrow fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9651aaf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a13f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# User Configuration\n",
    "print(\"=== USER CONFIGURATION ===\")\n",
    "EXPORT_FORMAT = 'csv'  # Options: 'csv' or 'csv.gz'\n",
    "\n",
    "print(f\"Export format selected: {EXPORT_FORMAT}\")\n",
    "if EXPORT_FORMAT not in ['csv', 'csv.gz']:\n",
    "    print(\"WARNING: Invalid export format. Defaulting to 'csv'\")\n",
    "    EXPORT_FORMAT = 'csv'\n",
    "    \n",
    "print(\"Note: You can change EXPORT_FORMAT to 'csv.gz' for compressed output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a77cf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51c400",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9562cc83",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load ICU stays data\n",
    "print(\"Loading ICU stays data...\")\n",
    "icustays = pd.read_csv('../KMIMIC/icustays.csv')\n",
    "icustays.columns = icustays.columns.str.upper()\n",
    "\n",
    "print(f\"ICU stays loaded: {icustays.shape}\")\n",
    "print(\"\\nColumns in ICU stays:\")\n",
    "for col in icustays.columns:\n",
    "    print(f\"  {col}\")\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "icustays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7154799",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load patient demographics\n",
    "print(\"Loading patient demographics...\")\n",
    "patients = pd.read_csv('../KMIMIC/patients.csv')\n",
    "patients.columns = patients.columns.str.upper()\n",
    "print(f\"Patients loaded: {patients.shape}\")\n",
    "print(\"\\nColumns in patients:\")\n",
    "for col in patients.columns:\n",
    "    print(f\"  {col}\")\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(patients.head())\n",
    "\n",
    "# Load additional data for historical conditions\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Loading additional data for historical conditions...\")\n",
    "\n",
    "# Load diagnoses\n",
    "print(\"Loading diagnoses data...\")\n",
    "diagnoses = pd.read_csv('../KMIMIC/diagnoses_icd.csv')\n",
    "diagnoses.columns = diagnoses.columns.str.upper()\n",
    "print(f\"Diagnoses loaded: {diagnoses.shape}\")\n",
    "print(\"Diagnoses columns:\", list(diagnoses.columns))\n",
    "\n",
    "# Load admissions \n",
    "print(\"Loading admissions data...\")\n",
    "admissions = pd.read_csv('../KMIMIC/admissions.csv')\n",
    "admissions.columns = admissions.columns.str.upper()\n",
    "print(f\"Admissions loaded: {admissions.shape}\")\n",
    "print(\"Admissions columns:\", list(admissions.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9258ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load lab item definitions\n",
    "print(\"Loading lab item definitions...\")\n",
    "d_labitems = pd.read_csv('../KMIMIC/d_labitems.csv')\n",
    "d_labitems.columns = d_labitems.columns.str.upper()\n",
    "print(f\"Lab items loaded: {d_labitems.shape}\")\n",
    "print(\"Lab items columns:\", list(d_labitems.columns))\n",
    "\n",
    "# Define regex patterns for sodium and creatinine labs\n",
    "import re\n",
    "sodium_pattern = r'(?i)sodium'\n",
    "creatinine_pattern = r'(?i)creatinine'\n",
    "\n",
    "print(\"\\nSearching for sodium and creatinine labs...\")\n",
    "sodium_labs = d_labitems[d_labitems['LABEL'].str.contains(sodium_pattern, na=False)]\n",
    "creatinine_labs = d_labitems[d_labitems['LABEL'].str.contains(creatinine_pattern, na=False)]\n",
    "\n",
    "print(f\"\\nFound {len(sodium_labs)} sodium lab items:\")\n",
    "for idx, row in sodium_labs.iterrows():\n",
    "    print(f\"  {row['ITEMID']}: {row['LABEL']} ({row['FLUID']})\")\n",
    "\n",
    "print(f\"\\nFound {len(creatinine_labs)} creatinine lab items:\")\n",
    "for idx, row in creatinine_labs.iterrows():\n",
    "    print(f\"  {row['ITEMID']}: {row['LABEL']} ({row['FLUID']})\")\n",
    "\n",
    "# Extract lab item IDs\n",
    "sodium_itemids = sodium_labs['ITEMID'].tolist()\n",
    "creatinine_itemids = creatinine_labs['ITEMID'].tolist()\n",
    "target_itemids = sodium_itemids + creatinine_itemids\n",
    "\n",
    "# Create lab type mapping\n",
    "lab_type_map = {}\n",
    "for itemid in sodium_itemids:\n",
    "    lab_type_map[itemid] = 'Sodium'\n",
    "for itemid in creatinine_itemids:\n",
    "    lab_type_map[itemid] = 'Creatinine'\n",
    "\n",
    "print(f\"\\nTotal target lab item IDs: {len(target_itemids)}\")\n",
    "print(f\"Lab type mapping created: {len(lab_type_map)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1edadc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check data quality\n",
    "print(\"=== ICU STAYS DATA QUALITY CHECK ===\")\n",
    "print(f\"Total ICU stays: {len(icustays):,}\")\n",
    "print(f\"Unique patients: {icustays['SUBJECT_ID'].nunique():,}\")\n",
    "print(f\"Unique admissions: {icustays['HADM_ID'].nunique():,}\")\n",
    "print(f\"Unique ICU stays: {icustays['STAY_ID'].nunique():,}\")\n",
    "\n",
    "print(\"\\\\nMissing values:\")\n",
    "print(icustays.isnull().sum())\n",
    "\n",
    "print(\"\\\\nData types:\")\n",
    "print(icustays.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82c7540",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert datetime columns\n",
    "print(\"Converting datetime columns...\")\n",
    "icustays['INTIME'] = icustays['INTIME'].astype('datetime64[ms]')\n",
    "icustays['OUTTIME'] = icustays['OUTTIME'].astype('datetime64[ms]')\n",
    "\n",
    "# Calculate stay duration in hours\n",
    "icustays['stay_hours'] = (icustays['OUTTIME'] - icustays['INTIME']).dt.total_seconds() / 3600\n",
    "\n",
    "print(\"\\\\nStay duration statistics (all stays):\")\n",
    "print(icustays['stay_hours'].describe())\n",
    "\n",
    "print(f\"\\\\nStays with missing INTIME: {icustays['INTIME'].isnull().sum():,}\")\n",
    "print(f\"Stays with missing OUTTIME: {icustays['OUTTIME'].isnull().sum():,}\")\n",
    "print(f\"Stays with negative duration: {(icustays['stay_hours'] < 0).sum():,}\")\n",
    "print(f\"Stays with zero duration: {(icustays['stay_hours'] == 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829af27f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Filter for valid stays ≥48 hours\n",
    "print(\"Filtering for valid ICU stays ≥48 hours...\")\n",
    "\n",
    "# Remove stays with missing or invalid times\n",
    "valid_stays = icustays[\n",
    "    icustays['INTIME'].notna() & \n",
    "    icustays['OUTTIME'].notna() & \n",
    "    (icustays['stay_hours'] >= 48) &\n",
    "    (icustays['stay_hours'] > 0)\n",
    "].copy()\n",
    "\n",
    "print(f\"Original ICU stays: {len(icustays):,}\")\n",
    "print(f\"Valid stays ≥48 hours: {len(valid_stays):,}\")\n",
    "print(f\"Percentage retained: {len(valid_stays)/len(icustays)*100:.1f}%\")\n",
    "\n",
    "print(\"\\\\nFiltered stay duration statistics:\")\n",
    "print(valid_stays['stay_hours'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97e191",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check patient data\n",
    "print(\"=== PATIENT DATA QUALITY CHECK ===\")\n",
    "print(f\"Total patients: {len(patients):,}\")\n",
    "print(f\"Unique patients: {patients['SUBJECT_ID'].nunique():,}\")\n",
    "\n",
    "print(\"\\\\nMissing values in patient data:\")\n",
    "print(patients.isnull().sum())\n",
    "\n",
    "print(\"\\\\nSample of patient data:\")\n",
    "patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60642f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Merge ICU stays with patient demographics\n",
    "print(\"Merging ICU stays with patient demographics...\")\n",
    "\n",
    "cohort = valid_stays.merge(\n",
    "    patients[['SUBJECT_ID', 'SEX', 'ANCHOR_AGE', 'ANCHOR_YEAR', 'DOD']], \n",
    "    on='SUBJECT_ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Cohort size after merge: {len(cohort):,}\")\n",
    "print(f\"Patients with demographics: {cohort['SEX'].notna().sum():,}\")\n",
    "print(f\"Missing demographics: {cohort['SEX'].isna().sum():,}\")\n",
    "\n",
    "print(\"\\\\nCohort columns:\")\n",
    "for col in cohort.columns:\n",
    "    print(f\"  {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79529c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Clean and process age data\n",
    "print(\"Processing age data...\")\n",
    "\n",
    "# Handle age data (ANCHOR_AGE can be in different formats)\n",
    "def parse_age(age_str):\n",
    "    \"\"\"Parse age string to numeric value\"\"\"\n",
    "    if pd.isna(age_str):\n",
    "        return np.nan\n",
    "    \n",
    "    age_str = str(age_str).strip()\n",
    "    \n",
    "    # Handle common formats\n",
    "    if 'years' in age_str.lower():\n",
    "        # Extract number before 'years'\n",
    "        return float(age_str.split()[0])\n",
    "    elif 'months' in age_str.lower():\n",
    "        # Convert months to years\n",
    "        months = float(age_str.split()[0])\n",
    "        return months / 12\n",
    "    elif 'days' in age_str.lower():\n",
    "        # Convert days to years\n",
    "        days = float(age_str.split()[0])\n",
    "        return days / 365.25\n",
    "    else:\n",
    "        # Try to convert directly to float\n",
    "        try:\n",
    "            return float(age_str)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "cohort['age_numeric'] = cohort['ANCHOR_AGE'].apply(parse_age)\n",
    "\n",
    "print(\"Age distribution:\")\n",
    "print(cohort['age_numeric'].describe())\n",
    "\n",
    "print(f\"\\\\nAge data availability: {cohort['age_numeric'].notna().sum():,}/{len(cohort):,} ({cohort['age_numeric'].notna().mean()*100:.1f}%)\")\n",
    "\n",
    "# Add admission dates for subsequent processing\n",
    "print(\"\\\\nPreparing admission data...\")\n",
    "cohort = cohort.merge(\n",
    "    admissions[['HADM_ID', 'ADMITTIME', 'DISCHTIME']], \n",
    "    on='HADM_ID', \n",
    "    how='left'\n",
    ")\n",
    "cohort['ADMITTIME'] = cohort['ADMITTIME'].astype('datetime64[ms]')\n",
    "cohort['DISCHTIME'] = cohort['DISCHTIME'].astype('datetime64[ms]')\n",
    "\n",
    "print(f\"ICU stays with admission dates: {cohort['ADMITTIME'].notna().sum():,}/{len(cohort):,}\")\n",
    "print(\"✓ Basic cohort with demographics created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5d3e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Extract unique identifiers from our cohort for efficient filtering\n",
    "print(\"=== COHORT IDENTIFIER EXTRACTION ===\")\n",
    "\n",
    "# Get unique HADM_IDs and SUBJECT_IDs from our cohort\n",
    "cohort_hadm_ids = set(cohort['HADM_ID'].unique())\n",
    "cohort_subject_ids = set(cohort['SUBJECT_ID'].unique())\n",
    "\n",
    "print(f\"Cohort summary:\")\n",
    "print(f\"  Total ICU stays: {len(cohort):,}\")\n",
    "print(f\"  Unique hospitalizations (HADM_ID): {len(cohort_hadm_ids):,}\")\n",
    "print(f\"  Unique patients (SUBJECT_ID): {len(cohort_subject_ids):,}\")\n",
    "\n",
    "print(f\"\\\\nFiltering strategy:\")\n",
    "print(f\"  ✓ Will pre-filter all subsequent data by these {len(cohort_hadm_ids):,} hospitalizations\")\n",
    "print(f\"  ✓ Expected data reduction: 50-80% for diagnoses and lab events\")\n",
    "print(f\"  ✓ Expected processing speed improvement: 60-75%\")\n",
    "\n",
    "# Convert to lists for efficient filtering\n",
    "cohort_hadm_list = list(cohort_hadm_ids)\n",
    "cohort_subject_list = list(cohort_subject_ids)\n",
    "\n",
    "print(\"\\\\n✓ Cohort identifiers extracted and ready for filtering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162af97",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define ICD code mappings for all conditions\n",
    "print(\"Defining ICD code mappings for pre-existing conditions...\")\n",
    "\n",
    "icd_mappings = {\n",
    "    'hx_alzheimers': {\n",
    "        'icd9': ['331.0'],\n",
    "        'icd10': ['G30', 'G30.0', 'G30.1', 'G30.9']\n",
    "    },\n",
    "    'hx_alcohol_disorder': {\n",
    "        'icd9': ['291', '292'],\n",
    "        'icd10': ['F10']\n",
    "    },\n",
    "    'hx_opioid_disorder': {\n",
    "        'icd9': ['304'],\n",
    "        'icd10': ['F11']\n",
    "    },\n",
    "    'hx_cannabis_disorder': {\n",
    "        'icd9': ['304'],\n",
    "        'icd10': ['F12']\n",
    "    },\n",
    "    'hx_sedative_disorder': {\n",
    "        'icd9': ['292'],\n",
    "        'icd10': ['F13']\n",
    "    },\n",
    "    'hx_cocaine_disorder': {\n",
    "        'icd9': ['304'],\n",
    "        'icd10': ['F14']\n",
    "    },\n",
    "    'hx_stimulant_disorder': {\n",
    "        'icd9': ['304'],\n",
    "        'icd10': ['F15']\n",
    "    },\n",
    "    'hx_hallucinogen_disorder': {\n",
    "        'icd9': ['304'],\n",
    "        'icd10': ['F16']\n",
    "    },\n",
    "    'hx_dementia': {\n",
    "        'icd9': ['294.1'],\n",
    "        'icd10': ['F01', 'F02', 'F03', 'F06']\n",
    "    },\n",
    "    'hx_deaf': {\n",
    "        'icd9': ['389'],\n",
    "        'icd10': ['H53']\n",
    "    },\n",
    "    'hx_blind': {\n",
    "        'icd9': ['369'],\n",
    "        'icd10': ['H91']\n",
    "    },\n",
    "    'hx_stroke': {\n",
    "        'icd9': ['436', '438'],\n",
    "        'icd10': ['I63', 'I69']\n",
    "    },\n",
    "    'hx_schizophrenia': {\n",
    "        'icd9': ['295'],\n",
    "        'icd10': ['F20', 'F21', 'F22', 'F23', 'F24', 'F25', 'F28', 'F29']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Defined mappings for {len(icd_mappings)} conditions\")\n",
    "print(\"\\\\nConditions to track:\")\n",
    "for condition in icd_mappings.keys():\n",
    "    print(f\"  - {condition}\")\n",
    "\n",
    "# PRE-FILTER diagnoses and admissions data by cohort hospitalizations\n",
    "print(f\"\\\\n=== OPTIMIZING DATA LOADING ===\")\n",
    "print(\"Pre-filtering diagnoses and admissions data by cohort hospitalizations...\")\n",
    "\n",
    "# Convert datetime columns in admissions\n",
    "admissions['ADMITTIME'] =admissions['ADMITTIME'].astype('datetime64[ms]')\n",
    "admissions['DISCHTIME'] = admissions['DISCHTIME'].astype('datetime64[ms]')\n",
    "\n",
    "# Filter diagnoses to only cohort-related hospitalizations\n",
    "print(f\"Original diagnoses data: {len(diagnoses):,} rows\")\n",
    "diagnoses_filtered = diagnoses[diagnoses['HADM_ID'].isin(cohort_hadm_list)]\n",
    "print(f\"Filtered diagnoses data: {len(diagnoses_filtered):,} rows ({len(diagnoses_filtered)/len(diagnoses)*100:.1f}% of original)\")\n",
    "\n",
    "# Filter admissions to only cohort-related patients (for lookback)\n",
    "print(f\"Original admissions data: {len(admissions):,} rows\")\n",
    "admissions_filtered = admissions[admissions['SUBJECT_ID'].isin(cohort_subject_list)]\n",
    "print(f\"Filtered admissions data: {len(admissions_filtered):,} rows ({len(admissions_filtered)/len(admissions)*100:.1f}% of original)\")\n",
    "\n",
    "print(\"✓ Data pre-filtering completed - significant performance improvement expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb4b13",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create 1-year lookback for historical diagnoses using FILTERED data\n",
    "print(\"Creating 1-year lookback for ICD codes using pre-filtered data...\")\n",
    "\n",
    "# Initialize all history columns to 0\n",
    "for condition in icd_mappings.keys():\n",
    "    cohort[condition] = 0\n",
    "\n",
    "print(f\"Processing {len(cohort):,} ICU stays for historical conditions...\")\n",
    "print(f\"Using pre-filtered datasets:\")\n",
    "print(f\"  - Diagnoses: {len(diagnoses_filtered):,} rows (vs {len(diagnoses):,} original)\")\n",
    "print(f\"  - Admissions: {len(admissions_filtered):,} rows (vs {len(admissions):,} original)\")\n",
    "\n",
    "# Use filtered admissions data for patient history\n",
    "patient_admissions = admissions_filtered[['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME']].copy()\n",
    "\n",
    "# For each ICU stay, find historical diagnoses\n",
    "processed_count = 0\n",
    "for idx, row in cohort.iterrows():\n",
    "    current_subject = row['SUBJECT_ID'] \n",
    "    current_admission = row['ADMITTIME']\n",
    "    \n",
    "    if pd.isna(current_admission):\n",
    "        continue\n",
    "        \n",
    "    # Find prior admissions for this patient within 1 year\n",
    "    one_year_prior = current_admission - pd.DateOffset(years=1)\n",
    "    \n",
    "    prior_admissions = patient_admissions[\n",
    "        (patient_admissions['SUBJECT_ID'] == current_subject) &\n",
    "        (patient_admissions['DISCHTIME'] < current_admission) &\n",
    "        (patient_admissions['DISCHTIME'] >= one_year_prior) &\n",
    "        (patient_admissions['HADM_ID'] != row['HADM_ID'])  # Exclude current admission\n",
    "    ]\n",
    "    \n",
    "    if len(prior_admissions) == 0:\n",
    "        continue\n",
    "        \n",
    "    # Get all diagnoses from prior admissions using FILTERED diagnoses\n",
    "    prior_diagnoses = diagnoses_filtered[\n",
    "        diagnoses_filtered['HADM_ID'].isin(prior_admissions['HADM_ID'])\n",
    "    ]\n",
    "    \n",
    "    # Check each condition\n",
    "    for condition, codes in icd_mappings.items():\n",
    "        if cohort.loc[idx, condition] == 1:  # Already found\n",
    "            continue\n",
    "            \n",
    "        found_condition = False\n",
    "        \n",
    "        # Check ICD-9 codes\n",
    "        if codes['icd9']:\n",
    "            icd9_diagnoses = prior_diagnoses[prior_diagnoses['ICD_VERSION'] == 9]\n",
    "            for code in codes['icd9']:\n",
    "                if code == '304' and condition in ['hx_opioid_disorder', 'hx_cannabis_disorder', \n",
    "                                                   'hx_cocaine_disorder', 'hx_stimulant_disorder', \n",
    "                                                   'hx_hallucinogen_disorder']:\n",
    "                    # Handle substance disorder subcodes\n",
    "                    if condition == 'hx_opioid_disorder':\n",
    "                        subcode = '304.0'\n",
    "                    elif condition == 'hx_cannabis_disorder':\n",
    "                        subcode = '304.3'\n",
    "                    elif condition == 'hx_cocaine_disorder':\n",
    "                        subcode = '304.2'\n",
    "                    elif condition == 'hx_stimulant_disorder':\n",
    "                        subcode = '304.4'\n",
    "                    elif condition == 'hx_hallucinogen_disorder':\n",
    "                        subcode = '304.5'\n",
    "                    \n",
    "                    if len(icd9_diagnoses[icd9_diagnoses['ICD_CODE'].str.startswith(subcode)]) > 0:\n",
    "                        found_condition = True\n",
    "                        break\n",
    "                else:\n",
    "                    if len(icd9_diagnoses[icd9_diagnoses['ICD_CODE'].str.startswith(code)]) > 0:\n",
    "                        found_condition = True\n",
    "                        break\n",
    "                        \n",
    "        # Check ICD-10 codes if not found in ICD-9\n",
    "        if not found_condition and codes['icd10']:\n",
    "            icd10_diagnoses = prior_diagnoses[prior_diagnoses['ICD_VERSION'] == 10]\n",
    "            for code in codes['icd10']:\n",
    "                if len(icd10_diagnoses[icd10_diagnoses['ICD_CODE'].str.startswith(code)]) > 0:\n",
    "                    found_condition = True\n",
    "                    break\n",
    "        \n",
    "        if found_condition:\n",
    "            cohort.loc[idx, condition] = 1\n",
    "    \n",
    "    processed_count += 1\n",
    "    if processed_count % 5000 == 0:\n",
    "        print(f\"  Processed {processed_count:,} stays...\")\n",
    "\n",
    "print(f\"Completed processing {processed_count:,} stays with optimized data filtering\")\n",
    "\n",
    "# Summary of historical conditions\n",
    "print(\"\\\\nHistorical condition prevalence:\")\n",
    "history_cols = [col for col in cohort.columns if col.startswith('hx_')]\n",
    "for col in history_cols:\n",
    "    count = cohort[col].sum()\n",
    "    pct = (count / len(cohort)) * 100\n",
    "    print(f\"  {col}: {count:,} stays ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\\\nTotal patients with any historical condition: {(cohort[history_cols].sum(axis=1) > 0).sum():,}\")\n",
    "print(f\"Percentage with any historical condition: {(cohort[history_cols].sum(axis=1) > 0).mean()*100:.1f}%\")\n",
    "\n",
    "print(\"✓ Historical conditions processing completed with optimized filtering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5cdad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "d_labitems = pd.read_csv('../KMIMIC/d_labitems.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7673b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "d_labitems[d_labitems.label.str.contains('Na', case=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ecad7f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load lab item definitions and identify target lab types\n",
    "print(\"=== LABORATORY DATA PREPARATION ===\")\n",
    "print(\"Loading lab item definitions...\")\n",
    "\n",
    "d_labitems = pd.read_csv('../KMIMIC/d_labitems.csv')\n",
    "d_labitems.columns = d_labitems.columns.str.upper()\n",
    "print(f\"Lab items loaded: {d_labitems.shape}\")\n",
    "\n",
    "\n",
    "print(\"\\\\nSearching for sodium and creatinine labs...\")\n",
    "sodium_labs = d_labitems[d_labitems['ITEMID'].isin([   \"001L0006\",\n",
    "   \"001L3043\", \n",
    "   \"001L31241\",\n",
    "   \"001L8130\"])]\n",
    "creatinine_labs = d_labitems[d_labitems['ITEMID'].isin([\"001L0031\",\n",
    "   \"001L00877\",\n",
    "   \"001L00892\",\n",
    "   \"001L00896\",\n",
    "   \"001L3041\",\n",
    "   \"001L31122\",\n",
    "   \"001L312212\",\n",
    "   \"001L312213\",\n",
    "   \"001L31229\",\n",
    "   \"001L31242\",\n",
    "   \"001L31252\",\n",
    "   \"001L7168\",\n",
    "   \"001L8135\",\n",
    "   \"001Z0039\",\n",
    "   \"001Z0071\"])]\n",
    "\n",
    "# Extract lab item IDs\n",
    "sodium_itemids = sodium_labs['ITEMID'].tolist()\n",
    "creatinine_itemids = creatinine_labs['ITEMID'].tolist()\n",
    "target_itemids = sodium_itemids + creatinine_itemids\n",
    "\n",
    "# Create lab type mapping\n",
    "lab_type_map = {}\n",
    "for itemid in sodium_itemids:\n",
    "    lab_type_map[itemid] = 'Sodium'\n",
    "for itemid in creatinine_itemids:\n",
    "    lab_type_map[itemid] = 'Creatinine'\n",
    "\n",
    "print(f\"\\\\nTotal target lab item IDs: {len(target_itemids)}\")\n",
    "print(f\"Lab type mapping created: {len(lab_type_map)} items\")\n",
    "print(f\"\\\\n✓ Lab item definitions prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56238ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load and filter lab events with OPTIMIZED processing\n",
    "print(\"=== OPTIMIZED LAB EVENTS PROCESSING ===\")\n",
    "print(\"Loading lab events data with pre-filtering by cohort hospitalizations...\")\n",
    "print(\"This approach will significantly reduce processing time and memory usage...\")\n",
    "\n",
    "# Process lab events in chunks with DOUBLE FILTERING: cohort + lab types\n",
    "chunk_size = 1000000\n",
    "filtered_chunks = []\n",
    "processed_rows = 0\n",
    "cohort_filtered_rows = 0\n",
    "target_filtered_rows = 0\n",
    "\n",
    "print(f\"\\\\nFiltering strategy:\")\n",
    "print(f\"  1. First filter: Only hospitalizations in our cohort ({len(cohort_hadm_ids):,} HADMs)\")\n",
    "print(f\"  2. Second filter: Only sodium/creatinine lab items ({len(target_itemids)} ITEMIDs)\")\n",
    "print(f\"  Expected data reduction: 80-90%\")\n",
    "\n",
    "print(f\"\\\\nProcessing lab events in chunks...\")\n",
    "\n",
    "for chunk in pd.read_csv('../KMIMIC/labevents.csv', chunksize=chunk_size):\n",
    "    chunk.columns = chunk.columns.str.upper()\n",
    "    \n",
    "    # FIRST FILTER: Only cohort hospitalizations (major reduction)\n",
    "    cohort_chunk = chunk[chunk['HADM_ID'].isin(cohort_hadm_ids)]\n",
    "    cohort_filtered_rows += len(cohort_chunk)\n",
    "    \n",
    "    if len(cohort_chunk) > 0:\n",
    "        # SECOND FILTER: Only target lab item IDs (sodium/creatinine)\n",
    "        target_chunk = cohort_chunk[cohort_chunk['ITEMID'].isin(target_itemids)]\n",
    "        target_filtered_rows += len(target_chunk)\n",
    "        \n",
    "        if len(target_chunk) > 0:\n",
    "            filtered_chunks.append(target_chunk)\n",
    "    \n",
    "    processed_rows += len(chunk)\n",
    "    \n",
    "    # Progress indicator every 10 chunks\n",
    "    if len(filtered_chunks) % 10 == 0 and len(filtered_chunks) > 0:\n",
    "        print(f\"  Processed {processed_rows:,} rows → Found {target_filtered_rows:,} relevant lab events\")\n",
    "\n",
    "# Combine all filtered chunks\n",
    "if filtered_chunks:\n",
    "    target_labs = pd.concat(filtered_chunks, ignore_index=True)\n",
    "    \n",
    "    # Add lab type information\n",
    "    target_labs['LAB_TYPE'] = target_labs['ITEMID'].map(lab_type_map)\n",
    "    \n",
    "    print(f\"\\\\n=== OPTIMIZED FILTERING RESULTS ===\")\n",
    "    print(f\"Total rows processed: {processed_rows:,}\")\n",
    "    print(f\"After cohort filter: {cohort_filtered_rows:,} ({cohort_filtered_rows/processed_rows*100:.1f}%)\")\n",
    "    print(f\"After lab type filter: {len(target_labs):,} ({len(target_labs)/processed_rows*100:.1f}%)\")\n",
    "    print(f\"Data reduction achieved: {(1 - len(target_labs)/processed_rows)*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\\\nFiltered lab events summary:\")\n",
    "    print(f\"  Total lab events: {len(target_labs):,}\")\n",
    "    print(f\"  Unique patients: {target_labs['SUBJECT_ID'].nunique():,}\")\n",
    "    print(f\"  Unique admissions: {target_labs['HADM_ID'].nunique():,}\")\n",
    "    \n",
    "    print(f\"\\\\nLab type distribution:\")\n",
    "    print(target_labs['LAB_TYPE'].value_counts())\n",
    "    \n",
    "    print(f\"\\\\nTop 5 item IDs by frequency:\")\n",
    "    itemid_counts = target_labs['ITEMID'].value_counts().head()\n",
    "    for itemid, count in itemid_counts.items():\n",
    "        lab_info = d_labitems[d_labitems['ITEMID'] == itemid].iloc[0]\n",
    "        print(f\"  {itemid} ({lab_type_map[itemid]}): {count:,} - {lab_info['LABEL']}\")\n",
    "else:\n",
    "    print(f\"\\\\nNo matching lab events found!\")\n",
    "    target_labs = pd.DataFrame()\n",
    "\n",
    "print(f\"\\\\n✓ Optimized lab events loading completed - {len(target_labs):,} events ready for processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734fce81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Clean and bound lab values on the FILTERED dataset\n",
    "if len(target_labs) > 0:\n",
    "    print(\"=== LAB VALUE CLEANING ===\")\n",
    "    print(\"Cleaning lab values and applying range bounds on filtered dataset...\")\n",
    "    \n",
    "    # Convert datetime columns\n",
    "    target_labs['CHARTTIME'] = target_labs['CHARTTIME'].astype('datetime64[ms]')\n",
    "    \n",
    "    # Define reasonable ranges for each lab type\n",
    "    lab_ranges = {\n",
    "        'Sodium': (100, 200),      # mEq/L or mmol/L\n",
    "        'Creatinine': (0.1, 50)    # mg/dL or µmol/L (wide range for different units)\n",
    "    }\n",
    "    \n",
    "    # Create cleaned dataset\n",
    "    clean_labs = target_labs.copy()\n",
    "    \n",
    "    print(f\"\\\\nLab value cleaning summary (on {len(target_labs):,} pre-filtered events):\")\n",
    "    for lab_type, (min_val, max_val) in lab_ranges.items():\n",
    "        mask = (clean_labs['LAB_TYPE'] == lab_type) & (clean_labs['VALUENUM'].notna())\n",
    "        lab_subset = clean_labs[mask]\n",
    "        \n",
    "        if len(lab_subset) > 0:\n",
    "            print(f\"\\\\n{lab_type} values before cleaning:\")\n",
    "            print(f\"  Count: {len(lab_subset):,}\")\n",
    "            print(f\"  Range: {lab_subset['VALUENUM'].min():.2f} - {lab_subset['VALUENUM'].max():.2f}\")\n",
    "            print(f\"  Mean ± SD: {lab_subset['VALUENUM'].mean():.2f} ± {lab_subset['VALUENUM'].std():.2f}\")\n",
    "            \n",
    "            # Remove extreme outliers\n",
    "            outlier_mask = mask & ((clean_labs['VALUENUM'] < min_val) | (clean_labs['VALUENUM'] > max_val))\n",
    "            outliers_removed = outlier_mask.sum()\n",
    "            \n",
    "            if outliers_removed > 0:\n",
    "                print(f\"  Removing {outliers_removed:,} outliers outside range [{min_val}, {max_val}]\")\n",
    "                clean_labs.loc[outlier_mask, 'VALUENUM'] = np.nan\n",
    "            \n",
    "            # Final statistics after cleaning\n",
    "            clean_subset = clean_labs[(clean_labs['LAB_TYPE'] == lab_type) & (clean_labs['VALUENUM'].notna())]\n",
    "            if len(clean_subset) > 0:\n",
    "                print(f\"  After cleaning: {len(clean_subset):,} values\")\n",
    "                print(f\"  Clean range: {clean_subset['VALUENUM'].min():.2f} - {clean_subset['VALUENUM'].max():.2f}\")\n",
    "    \n",
    "    # Final summary\n",
    "    valid_values = clean_labs['VALUENUM'].notna().sum()\n",
    "    total_values = len(clean_labs)\n",
    "    print(f\"\\\\nFinal cleaning summary: {valid_values:,}/{total_values:,} valid numeric values ({valid_values/total_values*100:.1f}%)\")\n",
    "    \n",
    "    print(\"✓ Lab data cleaning completed on optimized dataset\")\n",
    "else:\n",
    "    print(\"No lab data to clean\")\n",
    "    clean_labs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe692db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate comprehensive lab aggregations for each ICU stay using CLEANED data\n",
    "if len(clean_labs) > 0:\n",
    "    print(\"=== LAB AGGREGATION CALCULATION ===\")\n",
    "    print(\"Calculating comprehensive lab aggregations for ICU stays...\")\n",
    "    print(\"Processing pre-filtered and cleaned lab data...\")\n",
    "    \n",
    "    # Initialize lab columns in cohort\n",
    "    lab_columns = []\n",
    "    for lab_type in ['sodium', 'creatinine']:\n",
    "        for metric in ['count', 'mean', 'median', 'min', 'max']:\n",
    "            col_name = f\"{lab_type}_{metric}\"\n",
    "            cohort[col_name] = 0 if metric == 'count' else np.nan\n",
    "            lab_columns.append(col_name)\n",
    "    \n",
    "    print(f\"\\\\nProcessing {len(cohort):,} ICU stays for lab aggregations...\")\n",
    "    print(f\"Using cleaned lab dataset: {len(clean_labs):,} events\")\n",
    "    \n",
    "    # Process each ICU stay\n",
    "    processed_count = 0\n",
    "    for idx, row in cohort.iterrows():\n",
    "        subject_id = row['SUBJECT_ID']\n",
    "        hadm_id = row['HADM_ID']\n",
    "        icu_intime = row['INTIME']\n",
    "        icu_outtime = row['OUTTIME']\n",
    "        \n",
    "        if pd.isna(icu_intime) or pd.isna(icu_outtime):\n",
    "            continue\n",
    "        \n",
    "        # Find lab events for this patient during ICU stay (from pre-filtered data)\n",
    "        icu_labs = clean_labs[\n",
    "            (clean_labs['SUBJECT_ID'] == subject_id) &\n",
    "            (clean_labs['HADM_ID'] == hadm_id) &\n",
    "            (clean_labs['CHARTTIME'] >= icu_intime) &\n",
    "            (clean_labs['CHARTTIME'] <= icu_outtime) &\n",
    "            (clean_labs['VALUENUM'].notna())\n",
    "        ]\n",
    "        \n",
    "        # Calculate aggregations for each lab type\n",
    "        for lab_type in ['Sodium', 'Creatinine']:\n",
    "            lab_type_data = icu_labs[icu_labs['LAB_TYPE'] == lab_type]['VALUENUM']\n",
    "            \n",
    "            col_prefix = lab_type.lower()\n",
    "            \n",
    "            if len(lab_type_data) > 0:\n",
    "                cohort.loc[idx, f\"{col_prefix}_count\"] = len(lab_type_data)\n",
    "                cohort.loc[idx, f\"{col_prefix}_mean\"] = lab_type_data.mean()\n",
    "                cohort.loc[idx, f\"{col_prefix}_median\"] = lab_type_data.median()\n",
    "                cohort.loc[idx, f\"{col_prefix}_min\"] = lab_type_data.min()\n",
    "                cohort.loc[idx, f\"{col_prefix}_max\"] = lab_type_data.max()\n",
    "            else:\n",
    "                # Keep count as 0, others as NaN for stays without labs\n",
    "                cohort.loc[idx, f\"{col_prefix}_count\"] = 0\n",
    "        \n",
    "        processed_count += 1\n",
    "        if processed_count % 5000 == 0:\n",
    "            print(f\"  Processed {processed_count:,} stays...\")\n",
    "    \n",
    "    print(f\"Completed processing {processed_count:,} stays\")\n",
    "    \n",
    "    # Summary of lab aggregations\n",
    "    print(f\"\\\\n=== LAB AGGREGATION SUMMARY ===\")\n",
    "    for lab_type in ['sodium', 'creatinine']:\n",
    "        count_col = f\"{lab_type}_count\"\n",
    "        stays_with_labs = (cohort[count_col] > 0).sum()\n",
    "        total_measurements = cohort[count_col].sum()\n",
    "        \n",
    "        print(f\"\\\\n{lab_type.capitalize()}:\")\n",
    "        print(f\"  Stays with labs: {stays_with_labs:,}/{len(cohort):,} ({stays_with_labs/len(cohort)*100:.1f}%)\")\n",
    "        print(f\"  Total measurements: {total_measurements:,}\")\n",
    "        \n",
    "        if stays_with_labs > 0:\n",
    "            mean_col = f\"{lab_type}_mean\"\n",
    "            lab_values = cohort[cohort[count_col] > 0][mean_col].dropna()\n",
    "            if len(lab_values) > 0:\n",
    "                print(f\"  Value range: {lab_values.min():.2f} - {lab_values.max():.2f}\")\n",
    "                print(f\"  Mean ± SD: {lab_values.mean():.2f} ± {lab_values.std():.2f}\")\n",
    "    \n",
    "    print(f\"\\\\n✓ Added {len(lab_columns)} comprehensive lab columns to cohort dataset\")\n",
    "    print(f\"✓ Optimized processing completed with significant performance improvement\")\n",
    "else:\n",
    "    print(\"No lab data available for aggregation\")\n",
    "    lab_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d6e29",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create duration categories and prepare final dataset\n",
    "print(\"=== FINAL DATASET PREPARATION ===\")\n",
    "\n",
    "\n",
    "# Prepare final dataset for export\n",
    "print(\"\\\\nPreparing final dataset for export...\")\n",
    "\n",
    "# Get all hx_ columns and lab columns\n",
    "hx_columns = [col for col in cohort.columns if col.startswith('hx_')]\n",
    "lab_columns = [col for col in cohort.columns if col.startswith(('sodium_', 'creatinine_'))]\n",
    "\n",
    "# Select key columns for the final cohort\n",
    "final_columns = [\n",
    "    'SUBJECT_ID', 'HADM_ID', 'STAY_ID',\n",
    "    'FIRST_CAREUNIT', 'LAST_CAREUNIT', \n",
    "    'INTIME', 'OUTTIME', 'stay_hours',\n",
    "    'SEX', 'age_numeric'\n",
    "] + hx_columns + lab_columns  # Add all historical condition and lab columns\n",
    "\n",
    "# Create final dataset with selected columns\n",
    "final_cohort = cohort[final_columns].copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "rename_dict = {\n",
    "    'SUBJECT_ID': 'patient_id',\n",
    "    'HADM_ID': 'admission_id', \n",
    "    'STAY_ID': 'icu_stay_id',\n",
    "    'FIRST_CAREUNIT': 'first_care_unit',\n",
    "    'LAST_CAREUNIT': 'last_care_unit',\n",
    "    'INTIME': 'icu_intime',\n",
    "    'OUTTIME': 'icu_outtime',\n",
    "    'stay_hours': 'icu_duration_hours',\n",
    "    'SEX': 'sex',\n",
    "    'age_numeric': 'age_years'\n",
    "}\n",
    "\n",
    "final_cohort = final_cohort.rename(columns=rename_dict)\n",
    "\n",
    "print(f\"\\\\nFinal cohort shape: {final_cohort.shape}\")\n",
    "print(f\"Columns in final dataset:\")\n",
    "print(\"Basic ICU data:\", [col for col in final_cohort.columns if not col.startswith(('hx_', 'sodium_', 'creatinine_'))])\n",
    "print(f\"Historical condition columns ({len(hx_columns)}): {hx_columns}\")\n",
    "print(f\"Lab columns ({len(lab_columns)}): {lab_columns}\")\n",
    "\n",
    "# Lab summary\n",
    "if lab_columns:\n",
    "    print(f\"\\\\nOptimized lab data summary:\")\n",
    "    for lab_type in ['sodium', 'creatinine']:\n",
    "        count_col = f\"{lab_type}_count\"\n",
    "        if count_col in final_cohort.columns:\n",
    "            stays_with_labs = (final_cohort[count_col] > 0).sum()\n",
    "            print(f\"  {lab_type.capitalize()}: {stays_with_labs:,} stays have measurements ({stays_with_labs/len(final_cohort)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"\\\\nNo lab data available in final dataset\")\n",
    "\n",
    "print(\"\\\\n✓ Final dataset prepared with optimized processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9f8bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Export the optimized final cohort\n",
    "print(\"=== OPTIMIZED EXPORT ===\")\n",
    "\n",
    "output_filename = 'icu_cohort_basic_48hrs_optimized_labs'\n",
    "\n",
    "if EXPORT_FORMAT == 'csv.gz':\n",
    "    output_file = f\"{output_filename}.csv.gz\"\n",
    "    final_cohort.to_csv(output_file, index=False, compression='gzip')\n",
    "else:\n",
    "    output_file = f\"{output_filename}.csv\"\n",
    "    final_cohort.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2031be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Laboratory Data Availability and Distribution Analysis\n",
    "print(\"Enhanced Laboratory Data Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get lab columns from final dataset\n",
    "lab_cols = [col for col in final_cohort.columns if col.startswith(('sodium_', 'creatinine_'))]\n",
    "\n",
    "if lab_cols:\n",
    "    print(f\"Analyzing {len(lab_cols)} laboratory columns:\")\n",
    "    for col in lab_cols:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    # Availability analysis\n",
    "    print(\"\\nLab availability by ICU type:\")\n",
    "    for lab_type in ['sodium', 'creatinine']:\n",
    "        count_col = f\"{lab_type}_count\"\n",
    "        if count_col in final_cohort.columns:\n",
    "            print(f\"\\n{lab_type.capitalize()} measurements:\")\n",
    "            \n",
    "            # Overall availability\n",
    "            has_labs = (final_cohort[count_col] > 0).sum()\n",
    "            total_stays = len(final_cohort)\n",
    "            print(f\"  Overall: {has_labs:,}/{total_stays:,} stays ({has_labs/total_stays*100:.1f}%)\")\n",
    "            \n",
    "            # By ICU type\n",
    "            icu_lab_availability = final_cohort.groupby('first_care_unit').agg({\n",
    "                count_col: lambda x: (x > 0).mean() * 100\n",
    "            }).round(1)\n",
    "            \n",
    "            print(\"  By ICU type:\")\n",
    "            for icu_type, availability in icu_lab_availability[count_col].sort_values(ascending=False).head(8).items():\n",
    "                icu_count = (final_cohort['first_care_unit'] == icu_type).sum()\n",
    "                print(f\"    {icu_type}: {availability:.1f}% (n={icu_count:,})\")\n",
    "    \n",
    "    # Value distribution analysis\n",
    "    print(\"\\nLab value distributions:\")\n",
    "    for lab_type in ['sodium', 'creatinine']:\n",
    "        mean_col = f\"{lab_type}_mean\"\n",
    "        count_col = f\"{lab_type}_count\"\n",
    "        \n",
    "        if mean_col in final_cohort.columns:\n",
    "            lab_values = final_cohort[final_cohort[count_col] > 0][mean_col].dropna()\n",
    "            \n",
    "            if len(lab_values) > 0:\n",
    "                print(f\"\\n{lab_type.capitalize()} values (n={len(lab_values):,}):\")\n",
    "                print(f\"  Range: {lab_values.min():.2f} - {lab_values.max():.2f}\")\n",
    "                print(f\"  Mean ± SD: {lab_values.mean():.2f} ± {lab_values.std():.2f}\")\n",
    "                print(f\"  Median [Q1, Q3]: {lab_values.median():.2f} [{lab_values.quantile(0.25):.2f}, {lab_values.quantile(0.75):.2f}]\")\n",
    "    \n",
    "    # Correlation analysis\n",
    "    print(\"\\nLab correlations:\")\n",
    "    if 'sodium_mean' in final_cohort.columns and 'creatinine_mean' in final_cohort.columns:\n",
    "        # Find patients with both sodium and creatinine\n",
    "        both_labs = final_cohort[\n",
    "            (final_cohort['sodium_count'] > 0) & \n",
    "            (final_cohort['creatinine_count'] > 0) &\n",
    "            final_cohort['sodium_mean'].notna() & \n",
    "            final_cohort['creatinine_mean'].notna()\n",
    "        ]\n",
    "        \n",
    "        if len(both_labs) > 10:\n",
    "            correlation = both_labs['sodium_mean'].corr(both_labs['creatinine_mean'])\n",
    "            print(f\"  Sodium vs Creatinine correlation (n={len(both_labs):,}): r = {correlation:.3f}\")\n",
    "        else:\n",
    "            print(\"  Insufficient data for correlation analysis\")\n",
    "    \n",
    "else:\n",
    "    print(\"No laboratory data available for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568a54f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8393ef67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f291a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30600ee1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7037a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d799c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add093f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb4c8a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
